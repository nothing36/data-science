{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86695107",
   "metadata": {},
   "source": [
    "# Is this a cat or a keyboard?\n",
    "\n",
    "Run the below in the venv to make sure everything is installed beforehand\n",
    "\n",
    "`pip install -Uqq fastai 'duckduckgo_search>=6.2'`\n",
    "\n",
    "`pip install -U fastcore`\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedee63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket,warnings\n",
    "import os\n",
    "import time, json\n",
    "from duckduckgo_search import DDGS\n",
    "from fastcore.all import *\n",
    "from fastdownload import download_url\n",
    "from fastai.callback.tracker import EarlyStoppingCallback\n",
    "from fastai.vision.all import *\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a222b5",
   "metadata": {},
   "source": [
    "## Collect Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50296a8b",
   "metadata": {},
   "source": [
    "First we download an image of a cat and see how it looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd8891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use duckduckgo_search to grab images\n",
    "def search_images(keyword, max_images=200):\n",
    "    return L(DDGS().images(keyword, max_results=max_images)).itemgot('image')\n",
    "\n",
    "# grab 1 cat pic\n",
    "urls = search_images('cat', max_images=1)\n",
    "dest = 'cat.jpg'\n",
    "download_url(urls[0], dest, show_progress=False)\n",
    "cat_img = Image.open(dest)\n",
    "cat_img.to_thumb(256,256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08af6791",
   "metadata": {},
   "source": [
    "Next let's download an image of a keyboard too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891fe8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab 1 keyboard pic\n",
    "download_url(search_images('keyboard', max_images=1)[0], 'keyboard.jpg', show_progress=False)\n",
    "key_img = Image.open('keyboard.jpg').to_thumb(256,256)\n",
    "key_img.to_thumb(256,256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60e126e",
   "metadata": {},
   "source": [
    "Now let's download a bunch more pictures of cats and keyboards. These will be saved to their own seperate folders in this directory. This might take a sec..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83f4693",
   "metadata": {},
   "outputs": [],
   "source": [
    "searches = 'cat','keyboard'\n",
    "path = Path('cat_or_keyboard')\n",
    "\n",
    "# download\n",
    "for i in searches:\n",
    "    dest = (path/i)\n",
    "    dest.mkdir(exist_ok=True, parents=True)\n",
    "    download_images(dest, urls=search_images(f'{i} photo'))\n",
    "    time.sleep(5)\n",
    "    resize_images(path/i, max_size=400, dest=path/i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eda73c2",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2680378c",
   "metadata": {},
   "source": [
    "Check if all the images downloaded properly. Then we get rid of any bad downloads so they don't mess with our model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfec7789",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = verify_images(get_image_files(path))\n",
    "failed.map(Path.unlink)\n",
    "len(failed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd48ce48",
   "metadata": {},
   "source": [
    "Now to train the model we use DataLoaders. This will use a training set and a validation set. \n",
    "\n",
    "Remember the validation set is never used during training. It is only used for eval after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a69b616",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataBlock(\n",
    "    blocks = (ImageBlock, CategoryBlock), \n",
    "    get_items = get_image_files, \n",
    "    splitter = RandomSplitter(valid_pct=0.2, seed=42),\n",
    "    get_y = parent_label,\n",
    "    item_tfms = [Resize(192, method='squish')]\n",
    ").dataloaders(path, bs=32)\n",
    "\n",
    "# peek at some images\n",
    "dls.show_batch(max_n=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192d9d99",
   "metadata": {},
   "source": [
    "### DataBlock cheat code\n",
    "\n",
    "`blocks = (ImageBlock, CategoryBlock),`\n",
    "\n",
    "The model input will be images and we want categories for our output (\"cat\" and \"keyboard\")\n",
    "\n",
    "`get_items = get_image_files,`\n",
    "\n",
    "This will get all of the image files in whatever we set as `path`.\n",
    "\n",
    "`splitter = RandomSplitter(valid_pct=0.2, seed=42),`\n",
    "\n",
    "Now we split 20% of our data into the validation set.\n",
    "\n",
    "`get_y = parent_label,`\n",
    "\n",
    "Set the name of the parent of each file (\"cat\" or \"keyboard\")\n",
    "\n",
    "`item_tfms=[Resize(192, method='squish')]`\n",
    "\n",
    "Squish each image down to 192 x 192 px.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b11dd8",
   "metadata": {},
   "source": [
    "**And now we actually train...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91699b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet18, metrics=error_rate)\n",
    "\n",
    "# train up to 20 epochs. stop early if no longer improving\n",
    "learn.fine_tune(\n",
    "    20, \n",
    "    cbs=EarlyStoppingCallback(monitor='valid_loss', patience=3)  # wait at least 3 epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b75dab3",
   "metadata": {},
   "source": [
    "## Lets try it out\n",
    "\n",
    "Now we can use our model to check if that cat we downloaded earlier is actually a cat..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fedb61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict if cat or keyboard with a probability\n",
    "guess, _, prob = learn.predict(PILImage.create('cat.jpg'))\n",
    "print(f\"This is a: {guess}\")\n",
    "print(f\"with probability: {prob[0]:.6f}\")\n",
    "\n",
    "cat_img.to_thumb(256,256)   # show starting cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a25dd3",
   "metadata": {},
   "source": [
    "Or a keyboard..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4099127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict if cat or keyboard with a probability\n",
    "guess, _, prob = learn.predict(PILImage.create('keyboard.jpg'))\n",
    "print(f\"This is a: {guess}\")\n",
    "print(f\"with probability: {prob[1]:.6f}\")\n",
    "\n",
    "key_img.to_thumb(256,256)   # show starting keboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca859c0",
   "metadata": {},
   "source": [
    "Or run this cell to try an image saved at `test.jpg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab69d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = 'test.jpg'\n",
    "guess, _, prob = learn.predict(PILImage.create(test_file))\n",
    "print(f\"This is a: {guess}\")\n",
    "print(f\"with probability: {max(prob):.6f}\")\n",
    "\n",
    "# show image\n",
    "test_img = Image.open(test_file)\n",
    "test_img.to_thumb(256,256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9fede6",
   "metadata": {},
   "source": [
    "## Model analysis\n",
    "\n",
    "That was pretty simple, so now lets do a bit of analysis on how our model actually performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92885634",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, y_true = learn.get_preds(dl=dls.valid)\n",
    "y_pred = preds.argmax(dim=1)\n",
    "\n",
    "# generate classification report and convert to dataframe\n",
    "report = classification_report(y_true, y_pred, target_names=['cat', 'keyboard'], output_dict=True)\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "df_report = df_report.round(3)\n",
    "\n",
    "\n",
    "print(df_report[['precision', 'recall', 'f1-score']].iloc[:-3])\n",
    "print(f\"\\nOverall Accuracy: {df_report.loc['accuracy', 'f1-score']:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d94f07d",
   "metadata": {},
   "source": [
    "Now lets see how confident our model was at making these decisions. We'll start by plotting a chart showing how many images were classified at varying levels of confidence using our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dd5a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_np = preds.numpy()\n",
    "confidences = preds_np.max(axis=1)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(confidences, bins=20, edgecolor='black', alpha=0.7)\n",
    "plt.axvline(confidences.mean(), color='red', linestyle='--', label=f'Mean: {confidences.mean():.3f}')\n",
    "plt.xlabel('Prediction Confidence')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Model Confidence Distribution')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4442e8d5",
   "metadata": {},
   "source": [
    "Next, lets a chart showing the confidence scores given when the model was **correct**, and the confidence scores when the model was **wrong**. \n",
    "\n",
    "Remember, the boxplot's whiskers show the maximum and minimum values for the confidence levels. The top and bottom of the box correspond to the 75th and 25th percentile. The center corresponds to the median of the confidence levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fa6af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 2)\n",
    "errors = y_pred != y_true\n",
    "error_confidences = confidences[errors]\n",
    "correct_confidences = confidences[~errors]\n",
    "\n",
    "# create boxplot\n",
    "plt.boxplot([correct_confidences, error_confidences], tick_labels=['Correct', 'Incorrect'])\n",
    "plt.ylabel('Confidence Score')\n",
    "plt.title('Confidence by Prediction Correctness')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08330201",
   "metadata": {},
   "source": [
    "### So what does this all actually mean?\n",
    "\n",
    "Let's pretend we're running a company that offers a service to help users discern whether the picture they uploaded is of a cat or of a keyboard. Based off of our training and test data, we can get some key metrics for our customers and for our own insights. Let's calculate the average error rate of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76d9e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the metrics\n",
    "error_rate = errors.sum() / len(errors)\n",
    "avg_confidence = confidences.mean()\n",
    "low_confidence_threshold = 0.8\n",
    "low_confidence_preds = (confidences < low_confidence_threshold).sum()\n",
    "\n",
    "# print out stats for our work\n",
    "print(f\"- Error Rate: {error_rate:.2%}\")\n",
    "print(f\"  So our model misclassifies around {error_rate*100:.0f} out of 100 images\\n\")\n",
    "print(f\"- Average Confidence: {avg_confidence:.2%}\")\n",
    "print(f\"  Model is generally {'confident' if avg_confidence > 0.85 else 'uncertain'} in predictions\\n\")\n",
    "print(f\"- Low Confidence Predictions: {low_confidence_preds} ({low_confidence_preds/len(confidences):.2%})\")\n",
    "print(f\"  Due to low confidence, we might need employees to manually review {low_confidence_preds} images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04e92b9",
   "metadata": {},
   "source": [
    "We can also display a confusion matrix to give us a detailed breakdown into how our model actually classified everything.\n",
    "\n",
    "**Quick confusion matrix cheat sheet**:\n",
    "\n",
    "|                     | Predicted Positive  | Predicted Negative  |\n",
    "| ------------------- | ------------------- | ------------------- |\n",
    "| **Actual Positive** | True Positive (TP)  | False Negative (FN) |\n",
    "| **Actual Negative** | False Positive (FP) | True Negative (TN)  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a51676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmatrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# display the matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cmatrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Cat', 'Keyboard'], yticklabels=['Cat', 'Keyboard'])\n",
    "plt.title('Prediction Accuracy Matrix')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n",
    "\n",
    "# interpret the results\n",
    "false_positives = cmatrix[0, 1]  # cats predicted as keyboards\n",
    "false_negatives = cmatrix[1, 0]  # keyboards predicted as cats\n",
    "print(f\"- {false_positives} cats misclassified as keyboards\")\n",
    "print(f\"- {false_negatives} keyboards misclassified as cats\")\n",
    "\n",
    "# what is the model overpredicting\n",
    "if false_positives > false_negatives:\n",
    "    print(\"- Model tends to over-predict keyboards.\")\n",
    "else:\n",
    "    print(\"- Model tends to over-predict cats.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928dcfbe",
   "metadata": {},
   "source": [
    "Now finally lets get some actual insights for our \"Cat vs. Keyboard\" business so we can make some good decisions about the future of the company.\n",
    "\n",
    "### Scenario\n",
    "\n",
    "Assume our business employs \"Cat vs. Keyboard Specialists\" to make executive decisions on low-confidence predictions. Lets assume it takes on average **3 seconds** for one of these specialists to correctly classify an image. Let's say that our business gets around **10000** images sent in each day. These hypothetical employees are paid an hourly wage of **$18.00/hr**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3c1e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumptions\n",
    "wage_per_hour = 18.00\n",
    "sec_per_class = 3\n",
    "img_per_day = 10000\n",
    "\n",
    "# calculations\n",
    "review_fraction = low_confidence_preds / len(confidences)\n",
    "images_needing_review = review_fraction * img_per_day\n",
    "images_handled_by_ai = img_per_day - images_needing_review\n",
    "time_saved_hours = images_handled_by_ai * sec_per_class / 3600\n",
    "daily_cost_savings = time_saved_hours * wage_per_hour\n",
    "\n",
    "# analysis prinout\n",
    "print(\"If this classifier automated 10000 images each day:\")\n",
    "print(f\"- Accuracy: {(1 - error_rate):.1%}\")\n",
    "print(f\"- Images needing human review: {images_needing_review:.0f}\")\n",
    "print(f\"- Time saved: ~{time_saved_hours:.1f} hours/day\")\n",
    "print(f\"- Labor cost saved: ~${daily_cost_savings:,.2f} per day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b00d9f",
   "metadata": {},
   "source": [
    "Depending on what the model is over-predicting, we can gather more training data (images) less-predicted category and try this again. Since cats and keyboards come in a lot of different colours and in a lot of different settings, more diverse data could help us get even fewer errors.\n",
    "\n",
    "### END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
